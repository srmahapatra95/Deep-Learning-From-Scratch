{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd39725",
   "metadata": {},
   "source": [
    "# CNNs from scratch using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807962b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eac7b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NumPy Array Shapes ---\n",
      "X_train (Features): (1000, 1, 28, 28)\n",
      "y_train (Labels):   (1000,)\n",
      "X_test (Features):  (1000, 1, 28, 28)\n",
      "y_test (Labels):    (1000,)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # Convert image (PIL/Numpy) to PyTorch Tensor\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize the pixel values using MNIST's standard mean (0.1307) and std dev (0.3081)\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 2. Download and Load DataSets\n",
    "\n",
    "# Training Dataset (60,000 samples)\n",
    "mnist_train_dataset = datasets.MNIST(\n",
    "    root='./data',        # Directory where the data will be downloaded\n",
    "    train=True,           # Specify training data\n",
    "    download=True,        # Download if data is not already present\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Testing Dataset (10,000 samples)\n",
    "mnist_test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,          # Specify test data\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.cat([data[0].unsqueeze(0) for data in mnist_train_dataset], dim=0)\n",
    "y_train_tensor = mnist_train_dataset.targets\n",
    "X_test_tensor = torch.cat([data[0].unsqueeze(0) for data in mnist_test_dataset], dim=0)\n",
    "y_test_tensor = mnist_test_dataset.targets\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1. Convert Feature Tensors (X) to NumPy\n",
    "# We also flatten the images from (N, 1, 28, 28) to (N, 784) for ML libraries\n",
    "\n",
    "limit_img = 1000\n",
    "\n",
    "X_train_numpy = X_train_tensor.numpy().reshape(X_train_tensor.shape[0], 1, 28, 28)[0:limit_img]\n",
    "X_test_numpy = X_test_tensor.numpy().reshape(X_test_tensor.shape[0], 1, 28, 28)[0:limit_img]\n",
    "\n",
    "# 2. Convert Label Tensors (y) to NumPy\n",
    "\n",
    "y_train_numpy = y_train_tensor.numpy()[0:limit_img]\n",
    "y_test_numpy = y_test_tensor.numpy()[0:limit_img]\n",
    "\n",
    "print(\"--- NumPy Array Shapes ---\")\n",
    "print(f\"X_train (Features): {X_train_numpy.shape}\")\n",
    "print(f\"y_train (Labels):   {y_train_numpy.shape}\")\n",
    "print(f\"X_test (Features):  {X_test_numpy.shape}\")\n",
    "print(f\"y_test (Labels):    {y_test_numpy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e3f2c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_init(shape):\n",
    "    \"\"\"He initialization for ReLU networks.\"\"\"\n",
    "    std = np.sqrt(2.0 / np.prod(shape[1:]))\n",
    "    return np.random.randn(*shape) * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a70c8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride=1, padding=0):\n",
    "        self.C_in = C_in\n",
    "        self.C_out = C_out\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.W = he_init((C_out, C_in, kernel_size, kernel_size))\n",
    "        self.b = np.zeros((C_out,))\n",
    "\n",
    "        self.dW = np.zeros_like(self.W)\n",
    "        self.db = np.zeros_like(self.b)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X shape: (N, C_in, H_in, W_in)\n",
    "        self.X = X\n",
    "        N, C_in, H_in, W_in = X.shape\n",
    "        kH, kW = self.kernel_size, self.kernel_size\n",
    "        S = self.stride\n",
    "        P = self.padding\n",
    "\n",
    "        if P > 0:\n",
    "            X_padded = np.pad(X, ((0, 0), (0, 0), (P, P), (P, P)), mode='constant')\n",
    "        else:\n",
    "            X_padded = X\n",
    "    \n",
    "        H_pad, W_pad = X_padded.shape[2], X_padded.shape[3]\n",
    "        H_out = (H_pad - kH) // S + 1\n",
    "        W_out = (W_pad - kW) // S + 1\n",
    "\n",
    "        out = np.zeros((N, self.C_out, H_out, W_out))\n",
    "\n",
    "        for n in range(N):\n",
    "            for c_out in range(self.C_out):\n",
    "                for h in range(H_out):\n",
    "                    for w in range(W_out):\n",
    "                        h_start = h * S\n",
    "                        h_end = h_start + kH\n",
    "                        w_start = w * S\n",
    "                        w_end = w_start + kW\n",
    "\n",
    "                        region = X_padded[n, :, h_start:h_end, w_start:w_end] # C_in, kH, kW\n",
    "                        out[n, c_out, h, w] = np.sum(region * self.W[c_out]) + self.b[c_out]\n",
    "                        \n",
    "        self.x_padded = X_padded\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        X = self.X\n",
    "        N, C_in, H_in, W_in = X.shape\n",
    "        kH, kW = self.kernel_size, self.kernel_size\n",
    "        S = self.stride\n",
    "        P = self.padding\n",
    "\n",
    "        N, C_out, H_out, W_out = dout.shape\n",
    "\n",
    "        self.dW.fill(0)\n",
    "        self.db.fill(0)\n",
    "        dX_padded = np.zeros_like(self.x_padded)\n",
    "\n",
    "        for n in range(N):\n",
    "            for c_out in range(C_out):\n",
    "                for h in range(H_out):\n",
    "                    for w in range(W_out):\n",
    "                        \n",
    "                        h_start = h * S\n",
    "                        h_end = h_start + kH\n",
    "                        w_start = w * S\n",
    "                        w_end = w_start + kW\n",
    "\n",
    "                        region = self.x_padded[n, :, h_start:h_end, w_start:w_end] # C_in, kH, kW\n",
    "\n",
    "                        self.dW[c_out] += region * dout[n, c_out, h, w]\n",
    "                        self.db[c_out] += dout[n, c_out, h, w]\n",
    "                        dX_padded[n, :, h_start:h_end, w_start:w_end] += self.W[c_out] * dout[n, c_out, h, w]\n",
    "\n",
    "        if P > 0:\n",
    "            dX = dX_padded[:, :, P:-P, P:-P]\n",
    "        else:\n",
    "            dX = dX_padded\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "142ec87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def forward(self, X):\n",
    "        self.mask = (X>0)\n",
    "        return X * self.mask\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "33824db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "\n",
    "    def __init__(self, pool_size, stride):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X shape: (N, C, H, W)\n",
    "        self.X = X  # Store input for backward pass\n",
    "        N, C, H, W = X.shape\n",
    "        pH, pW = self.pool_size, self.pool_size\n",
    "        S = self.stride\n",
    "\n",
    "        H_out = (H - pH) // S + 1\n",
    "        W_out = (W - pW) // S + 1\n",
    "\n",
    "        self.max_indices = {}\n",
    "        self.out_shape = (N, C, H_out, W_out)\n",
    "\n",
    "        out = np.zeros((N, C, H_out, W_out))\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for h in range(H_out):\n",
    "                    for w in range(W_out):\n",
    "                        h_start = h * S\n",
    "                        h_end  = h_start + pH\n",
    "                        w_start = w * S\n",
    "                        w_end  = w_start + pW\n",
    "\n",
    "                        region = X[n, c, h_start:h_end, w_start:w_end]\n",
    "                        out[n, c, h, w] = np.max(region)\n",
    "                        idx = np.argmax(region)\n",
    "                        self.max_indices[(n, c, h, w)] = (int(h_start + idx // pW), int(w_start + idx % pW))\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, C, H, W = self.X.shape\n",
    "        pH, pW = self.pool_size, self.pool_size\n",
    "        S = self.stride\n",
    "        \n",
    "        dx = np.zeros_like(self.X)\n",
    "\n",
    "        _, _, H_out, W_out = dout.shape\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for h in range(H_out):\n",
    "                    for w in range(W_out):\n",
    "                        grad = dout[n, c, h, w]\n",
    "                        h_idx, w_idx = self.max_indices[(n, c, h, w)]\n",
    "                        dx[n, c, h_idx, w_idx] += grad\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "98b9f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, X):\n",
    "        self.input_shape = X.shape\n",
    "        N = X.shape[0]\n",
    "        return X.reshape(N, -1)\n",
    "    \n",
    "    def _get_flattened_size(self):\n",
    "        return np.prod(self.input_shape[1:])\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "961c8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.W = he_init((input_dim, output_dim))\n",
    "        self.b = np.zeros((output_dim,))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return np.dot(X, self.W) + self.b\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.dW = np.dot(self.X.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "772e84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxCrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        exps = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "        probs = exps / np.sum(exps, axis=1, keepdims=True)\n",
    "        N = X.shape[0]\n",
    "        correct_logprobs = -np.log(probs[range(N), y] + 1e-10)\n",
    "        loss = np.sum(correct_logprobs) / N\n",
    "        self.probs = probs\n",
    "        self.y = y\n",
    "        return loss, probs\n",
    "    \n",
    "    def backward(self, y=None):\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "        probs = self.probs.copy()\n",
    "        N = probs.shape[0]\n",
    "        probs[range(N), y] -= 1\n",
    "        probs /= N\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9a8562c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, pool_size, stride, padding, num_classes):\n",
    "        self.C_in = C_in\n",
    "        self.C_out = C_out\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv = Conv2D(C_in, C_out, kernel_size, stride, padding)\n",
    "        self.relu = Relu()\n",
    "        self.pool = MaxPool2D(pool_size, stride)\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        # Calculate flattened size: (28, 28) -> conv -> pool -> flatten\n",
    "        # After conv: H_out = (28 + 2*1 - 3) / 1 + 1 = 28\n",
    "        # After pool with stride=1: H_out = (28 - 2) / 1 + 1 = 27\n",
    "        # Flattened: C_out * 27 * 27 = 16 * 729 = 11664\n",
    "        H_after_conv = (28 + 2 * padding - kernel_size) // stride + 1\n",
    "        H_after_pool = (H_after_conv - pool_size) // stride + 1\n",
    "        flattened_size = C_out * H_after_pool * H_after_pool\n",
    "        \n",
    "        self.fc = Linear(flattened_size, num_classes)\n",
    "        self.criterion = SoftMaxCrossEntropy()\n",
    "\n",
    "        self.params = [self.conv, self.fc]\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        out = self.conv.forward(X)\n",
    "        out = self.relu.forward(out)\n",
    "        out = self.pool.forward(out)\n",
    "        out = self.flatten.forward(out)\n",
    "        logits = self.fc.forward(out)\n",
    "\n",
    "        if y is None:\n",
    "            return logits\n",
    "        \n",
    "        loss, probs = self.criterion.forward(logits, y)\n",
    "        return loss, probs\n",
    "\n",
    "    def backward(self):\n",
    "        dlogits = self.criterion.backward(self.y)\n",
    "        dout = self.fc.backward(dlogits)\n",
    "        dout = self.flatten.backward(dout)\n",
    "        dout = self.pool.backward(dout)\n",
    "        dout = self.relu.backward(dout)\n",
    "        dx = self.conv.backward(dout)\n",
    "\n",
    "        return dx\n",
    "\n",
    "    def step(self, learning_rate=1e-3):\n",
    "        for layer in self.params:\n",
    "            layer.W -= learning_rate * layer.dW\n",
    "            layer.b -= learning_rate * layer.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "386d1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    logits = model.forward(X, None)\n",
    "    return np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7c9304d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, epochs = 5, batch_size = 32, learning_rate = 1e-3):\n",
    "    num_samples = X_train.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / batch_size))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start = batch_idx * batch_size\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            X_batch = X_train[start:end]\n",
    "            y_batch = y_train[start:end]\n",
    "\n",
    "            loss, _ = model.forward(X_batch, y_batch)\n",
    "            model.y = y_batch  # Store y for backward pass\n",
    "            epoch_loss += loss\n",
    "\n",
    "            # Calculate accuracy for this batch\n",
    "            predictions = predict(model, X_batch)\n",
    "            correct_predictions += np.sum(predictions == y_batch)\n",
    "            total_predictions += y_batch.shape[0]\n",
    "\n",
    "            model.backward()\n",
    "            model.step(learning_rate)\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4d09c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_in = 1\n",
    "C_out = 16\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "stride = 1\n",
    "padding = 1\n",
    "num_classes = 10\n",
    "model = SimpleCNN(C_in, C_out, kernel_size, pool_size, stride, padding, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2a7887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 18.0136, Accuracy: 0.1210\n",
      "Epoch 2/15, Loss: 13.2340, Accuracy: 0.2110\n",
      "Epoch 2/15, Loss: 13.2340, Accuracy: 0.2110\n",
      "Epoch 3/15, Loss: 9.8150, Accuracy: 0.2960\n",
      "Epoch 3/15, Loss: 9.8150, Accuracy: 0.2960\n",
      "Epoch 4/15, Loss: 7.9511, Accuracy: 0.3580\n",
      "Epoch 4/15, Loss: 7.9511, Accuracy: 0.3580\n",
      "Epoch 5/15, Loss: 6.7290, Accuracy: 0.3740\n",
      "Epoch 5/15, Loss: 6.7290, Accuracy: 0.3740\n",
      "Epoch 6/15, Loss: 5.8548, Accuracy: 0.3910\n",
      "Epoch 6/15, Loss: 5.8548, Accuracy: 0.3910\n",
      "Epoch 7/15, Loss: 5.2021, Accuracy: 0.4120\n",
      "Epoch 7/15, Loss: 5.2021, Accuracy: 0.4120\n",
      "Epoch 8/15, Loss: 4.6610, Accuracy: 0.4180\n",
      "Epoch 8/15, Loss: 4.6610, Accuracy: 0.4180\n",
      "Epoch 9/15, Loss: 4.2015, Accuracy: 0.4250\n",
      "Epoch 9/15, Loss: 4.2015, Accuracy: 0.4250\n",
      "Epoch 10/15, Loss: 3.8296, Accuracy: 0.4240\n",
      "Epoch 10/15, Loss: 3.8296, Accuracy: 0.4240\n",
      "Epoch 11/15, Loss: 3.5268, Accuracy: 0.4240\n",
      "Epoch 11/15, Loss: 3.5268, Accuracy: 0.4240\n",
      "Epoch 12/15, Loss: 3.2570, Accuracy: 0.4340\n",
      "Epoch 12/15, Loss: 3.2570, Accuracy: 0.4340\n",
      "Epoch 13/15, Loss: 3.0211, Accuracy: 0.4460\n",
      "Epoch 13/15, Loss: 3.0211, Accuracy: 0.4460\n",
      "Epoch 14/15, Loss: 2.8205, Accuracy: 0.4530\n",
      "Epoch 14/15, Loss: 2.8205, Accuracy: 0.4530\n",
      "Epoch 15/15, Loss: 2.6370, Accuracy: 0.4600\n",
      "Epoch 15/15, Loss: 2.6370, Accuracy: 0.4600\n"
     ]
    }
   ],
   "source": [
    "train(model, X_train_numpy, y_train_numpy, epochs = 15, batch_size = 20, learning_rate = 1e-3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
